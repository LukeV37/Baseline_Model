{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d3007db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "import torch\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.data import Dataset, Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63d22b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyOwnDataset(Dataset):\n",
    "    def __init__(self, root, test=False, transform=None, pre_transform=None, pre_filter=None):\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self): # Returns a list of file names found in the raw directory\n",
    "        return ['train_data.txt', 'train_edges.txt', 'test_data.txt', 'test_edges.txt']\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self): # Returns a list of file names that were already procesed\n",
    "        return ['data_train.pt', 'data_test.pt']\n",
    "\n",
    "    def download(self): # Files to download\n",
    "        pass\n",
    "    \n",
    "    def feature_normalize(self, mx):\n",
    "        \"\"\"Row-normalize sparse matrix\"\"\"\n",
    "        rowsum = np.array(mx.sum(1))\n",
    "        r_inv = np.power(rowsum, -1).flatten()\n",
    "        r_inv[np.isinf(r_inv)] = 0.\n",
    "        r_mat_inv = sp.diags(r_inv)\n",
    "        mx = r_mat_inv.dot(mx)\n",
    "        return mx\n",
    "    \n",
    "    def adj_normalize(self, mx):\n",
    "        \"\"\"Row-normalize sparse matrix\"\"\"\n",
    "        rowsum = np.array(mx.sum(1)) # Sum each row\n",
    "        r_inv = np.power(rowsum, -1/2).flatten() # Negative square root\n",
    "    #     r_inv[np.isinf(r_inv)] = 0.\n",
    "        r_mat_inv = sp.diags(r_inv) # Create diagonal matrix\n",
    "\n",
    "        # D^(-1/2).A.D^(-1/2)\n",
    "        mx = r_mat_inv.dot(mx)\n",
    "        mx = mx.dot(r_mat_inv)\n",
    "        return mx\n",
    "    \n",
    "    def sparse_mx_to_torch_sparse_tensor(self, sparse_mx):\n",
    "        \"\"\"Convert a scipy sparse matrix to a torch sparse tensor.\"\"\"\n",
    "        sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
    "        indices = torch.from_numpy(\n",
    "            np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n",
    "#         values = torch.from_numpy(sparse_mx.data)\n",
    "#         shape = torch.Size(sparse_mx.shape)\n",
    "#         return torch.sparse.FloatTensor(indices, values, shape)\n",
    "        return indices\n",
    "    \n",
    "    def encode_onehot(self, labels):\n",
    "        classes = set(labels)\n",
    "        classes_dict = {c: np.identity(len(classes))[i, :] for i, c in enumerate(classes)}\n",
    "        labels_onehot = np.array(list(map(classes_dict.get, labels)), dtype=np.int32)\n",
    "        return labels_onehot\n",
    "\n",
    "    def organize_data(self, which):\n",
    "        if which == 'train':\n",
    "            data_path = os.path.join(self.raw_dir, 'train_data.txt')\n",
    "            edges_path = os.path.join(self.raw_dir, 'train_edges.txt')\n",
    "        else:\n",
    "            data_path = os.path.join(self.raw_dir, 'test_data.txt')\n",
    "            edges_path = os.path.join(self.raw_dir, 'test_edges.txt')\n",
    "            \n",
    "        idx_features_labels = np.genfromtxt(data_path, dtype=np.dtype(str))\n",
    "        \n",
    "        num_feats = 19\n",
    "        features = sp.csr_matrix(idx_features_labels[:, 0:num_feats], dtype=np.float32) # Processing features into a sparse matrix\n",
    "        labels = self.encode_onehot(idx_features_labels[:, -2]) # one-hot encoding the labels\n",
    "        \n",
    "        # build graph\n",
    "        idx = np.array(idx_features_labels[:, -1], dtype=np.int32) # Reading node-ids\n",
    "\n",
    "        # Creating node ids to eliminate discrepencies in node ids in the data\n",
    "        idx_map = {j: i for i, j in enumerate(idx)} # Creating index for nodes to map it in adjacency matrix\n",
    "        \n",
    "        edges_unordered = np.genfromtxt(edges_path, dtype=np.int32) # Reading edges\n",
    "        edges = np.array(list(map(idx_map.get, edges_unordered.flatten())),\n",
    "                     dtype=np.int32).reshape(edges_unordered.shape) # Mapping node-ids in the edge list to the index\n",
    "        \n",
    "        # Build adjacency matrix\n",
    "        adj = sp.coo_matrix((np.ones(edges.shape[0]), (edges[:, 0], edges[:, 1])),\n",
    "                        shape=(labels.shape[0], labels.shape[0]),\n",
    "                        dtype=np.float32)\n",
    "        \n",
    "        print(adj.shape)\n",
    "        \n",
    "        # Normalizing features\n",
    "        features = self.feature_normalize(features)\n",
    "        \n",
    "        adj = self.adj_normalize(adj + sp.eye(adj.shape[0]))\n",
    "        \n",
    "        features = torch.FloatTensor(np.array(features.todense()))\n",
    "        labels = torch.LongTensor(np.where(labels)[1])\n",
    "        adj = self.sparse_mx_to_torch_sparse_tensor(adj)\n",
    "        \n",
    "        \n",
    "        data = Data(x=features, edge_index=adj, y=labels)\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    def process(self):\n",
    "        # processing training data\n",
    "        train_data = self.organize_data('train')\n",
    "        torch.save(train_data, os.path.join(self.processed_dir, 'data_train.pt'))\n",
    "        \n",
    "        # processing test data\n",
    "        test_data = self.organize_data('test')\n",
    "        torch.save(test_data, os.path.join(self.processed_dir, 'data_test.pt'))\n",
    "\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.processed_file_names)\n",
    "\n",
    "    def get(self, which):\n",
    "        if which == 'train':\n",
    "            data = torch.load(os.path.join(self.processed_dir, 'data_train.pt'))\n",
    "        elif which == 'test':\n",
    "            data = torch.load(os.path.join(self.processed_dir, 'data_test.pt'))\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ace81517",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2038461, 2038461)\n",
      "(679547, 679547)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "filepath = 'data/wtracks/ttbar/'\n",
    "dataset = MyOwnDataset(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db5cf281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2038461\n",
      "35235779\n",
      "19\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "# print('Training data details')\n",
    "data = dataset.get('train')\n",
    "\n",
    "print(data.num_nodes)\n",
    "print(data.num_edges)\n",
    "print(data.num_features)\n",
    "print(data.num_node_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b36dff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "679547\n",
      "11696875\n",
      "19\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "# print('Test data details')\n",
    "data = dataset.get('test')\n",
    "\n",
    "print(data.num_nodes)\n",
    "print(data.num_edges)\n",
    "print(data.num_features)\n",
    "print(data.num_node_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c2fdd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
